{"id": "problem-framer-008", "title": "MVP solves measurement, not validation", "issue": "Phase 1 validates 'Inspect AI works' not 'parallax skills work.' Finding quality scorer is deferred to Phase 2, meaning MVP cannot answer the core question: do skills catch real design flaws?", "severity": "Critical", "reviewer": "problem-framer", "min_recall": 0.8}
{"id": "scope-guardian-013", "title": "Confidence measurement undefined", "issue": "FR2.3 requires flagging findings where model has <95% confidence but does not define how confidence is measured. Without a definition the requirement is unimplementable and blocks the manual validation workflow.", "severity": "Critical", "reviewer": "scope-guardian", "min_recall": 0.8}
{"id": "assumption-hunter-013", "title": "Confidence measurement undefined", "issue": "The 95% confidence threshold is used as a decision gate in FR2.1 and FR3.3, but the document never defines what confidence means or how it is calculated. Whether confidence is a human judgment, a model probability score, or something else is unspecified. The threshold is unimplementable without a measurement method.", "severity": "Critical", "reviewer": "assumption-hunter", "min_recall": 0.7}
{"id": "success-validator-001", "title": "Detection rate has no target thresholds", "issue": "FR2.2 specifies recall, precision, and F1 metrics but provides no target values. Cannot determine pass or fail without quantified thresholds.", "severity": "Critical", "reviewer": "success-validator", "min_recall": 0.8}
{"id": "success-validator-002", "title": "Ablation test baseline undefined", "issue": "FR4.1 references 'detection rate X%' as baseline but X is never defined anywhere. The ablation test condition 'detection rate < (X - 50)%' cannot run without a value for X.", "severity": "Critical", "reviewer": "success-validator", "min_recall": 0.8}
