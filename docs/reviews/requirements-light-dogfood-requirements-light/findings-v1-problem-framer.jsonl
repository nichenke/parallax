{"type": "finding", "id": "v1-problem-framer-001", "title": "Root cause vs symptom framing unclear - is brainstorming output quality the real problem?", "severity": "Critical", "phase": {"primary": "calibrate", "contributing": "survey"}, "section": "Overview", "issue": "Design assumes brainstorming output lacks requirement clarity, but doesn't establish whether this is a root cause (brainstorming skill produces incomplete requirements) or symptom (users invoke brainstorming incorrectly, or skip requirement thinking). The problem statement 'catches requirement gaps after brainstorming' presumes gaps exist systematically but provides no evidence.", "why_it_matters": "If root cause is user behavior (rushing past requirements thinking), adding a checkpoint won't fix it - users will skip this too. If root cause is brainstorming skill limitations, solution should improve brainstorming, not add post-processing. Wrong problem framing leads to building the wrong solution.", "suggestion": "Add evidence section: 'Why this problem exists' with specific examples from past brainstorming sessions showing requirement gaps that caused rework. Distinguish between skill output quality issues vs user workflow issues. If no evidence exists, this becomes a hypothesis to validate, not a problem to solve."}
{"type": "finding", "id": "v1-problem-framer-002", "title": "Success criteria conflate validation metrics with value metrics", "severity": "Important", "phase": {"primary": "calibrate", "contributing": null}, "section": "Goals", "issue": "Success criteria mix quality validation ('Catches 3-5 real requirement gaps', 'Findings are actionable') with adoption validation ('Users naturally remember to invoke'). These measure different things: one measures skill effectiveness, other measures workflow fit. Design doesn't establish which is more important or what happens if they conflict (e.g., skill is effective but users forget to invoke).", "why_it_matters": "If users don't remember to invoke despite skill being effective, MVP fails on adoption but succeeds on quality. Without priority, can't determine if MVP succeeded or failed. Different success dimensions require different solution paths.", "suggestion": "Separate success criteria into two tiers: (1) Quality bar: 'If invoked, skill must catch 3-5 real gaps with >70% precision' (go/no-go), (2) Adoption bar: 'Users invoke after brainstorming >60% of the time' (hypothesis validation). Specify which is primary MVP success criterion."}
{"type": "finding", "id": "v1-problem-framer-003", "title": "Problem scope excludes mid-design requirement drift", "severity": "Important", "phase": {"primary": "calibrate", "contributing": null}, "section": "Workflow Integration", "issue": "Problem framed as 'post-brainstorm checkpoint' but design exploration often reveals new requirements mid-design (MEMORY.md notes 'requirements emerge through design'). Two-checkpoint model (light + deep) addresses this but design doesn't explain why two checkpoints solve the problem better than continuous requirement tracking or single post-design checkpoint.", "why_it_matters": "If requirements truly emerge through design, light checkpoint may catch wrong class of gaps (problem framing) while missing the higher-impact class (specification gaps discovered during design). Design may be solving an easier but lower-value problem. Value proposition depends on whether post-brainstorm gaps cause more rework than mid-design gaps.", "suggestion": "Add analysis: 'Why two checkpoints' with specific examples of requirement gaps caught at each stage. Quantify relative impact: what % of rework comes from post-brainstorm gaps vs mid-design gaps? If unknown, make this explicit hypothesis to test."}
{"type": "finding", "id": "v1-problem-framer-004", "title": "Value proposition assumes requirement gaps cause rework, but doesn't quantify rework cost", "severity": "Important", "phase": {"primary": "calibrate", "contributing": null}, "section": "Goals", "issue": "Success criteria specify 'catches 3-5 real requirement gaps that would cause rework if missed' but doesn't define 'rework' severity or establish whether 30min review investment is cheaper than fixing gaps later. Some requirement gaps might be trivial to fix after design (5min edits), others catastrophic (redesign). Design doesn't distinguish or quantify.", "why_it_matters": "Without rework cost analysis, can't validate if 30min upfront investment has positive ROI. If average gap costs 2min to fix later, catching 5 gaps saves 10min but costs 30min - negative ROI. Need evidence that typical requirement gaps are expensive to fix post-design.", "suggestion": "Add section 'Cost-benefit analysis' estimating typical rework cost per requirement gap class (scope ambiguity, missing constraint, undefined success criteria). Use past brainstorming sessions as evidence. Define ROI threshold: e.g., 'Review worth it if it prevents >1 hour of rework.'"}
{"type": "finding", "id": "v1-problem-framer-005", "title": "Problem framing assumes universal applicability but design admits variable value", "severity": "Minor", "phase": {"primary": "calibrate", "contributing": null}, "section": "Design Decisions", "issue": "Design Decisions section states 'Not all projects need formal requirements docs' and 'Avoid forcing process on projects that don't need it', implicitly admitting problem isn't universal. But Goals section frames problem as if all brainstorming outputs need requirements review. Tension between universal problem framing and conditional value proposition.", "why_it_matters": "If value is conditional on project complexity, success criteria should include 'works well for projects that need it, gracefully skips for projects that don't' rather than 'users naturally remember to invoke'. Currently design may fail on simple projects where gaps don't matter, artificially lowering success metrics.", "suggestion": "Add to Goals: 'Project applicability: Requirements review adds value for projects with [characteristics]. For simple projects, skill should quickly determine review unnecessary and exit.' Define project characteristics where value is high vs low."}
