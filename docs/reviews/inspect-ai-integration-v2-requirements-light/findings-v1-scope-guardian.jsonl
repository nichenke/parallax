{"type": "finding", "id": "scope-guardian-001", "title": "Phase 1.5 multi-model comparison lacks a clear deferral gate", "severity": "Important", "phase": {"primary": "calibrate", "contributing": null}, "section": "MVP Phase Map (updated from v1)", "issue": "Phase 1.5 (Sonnet vs Haiku multi-model comparison) is listed as 'Not started' with a blocking dependency on a Google account and cost budget spec, yet it is not listed in the 'Explicitly Out of Scope' section. Its inclusion in the phase map without a clear exclusion from MVP scope blurs the MVP boundary. If Phase 1.5 is not needed to unblock Phase 2, it should be explicitly deferred.", "why_it_matters": "Ambiguous phases become implicit scope. Engineers and reviewers treating the phase map as a roadmap may treat Phase 1.5 as in-flight work requiring decisions, diverting effort from the Phase 1 unblocking work. The MVP definition should be binary: Phase 1 is the MVP, everything else is deferred.", "suggestion": "Move Phase 1.5 to the 'Explicitly Out of Scope (v2)' deferred list with a clear note: 'Deferred until Phase 1 produces non-zero accuracy and a stable detection baseline.' Remove it from the phase map or clearly label it as 'Post-MVP.'"}
{"type": "finding", "id": "scope-guardian-002", "title": "FR-ARCH-5 cost budget is in-scope but unenforceable in Phase 1", "severity": "Important", "phase": {"primary": "calibrate", "contributing": null}, "section": "FR-ARCH-5: Cost Budget Per Eval Suite Run", "issue": "FR-ARCH-5 requires `make cost-report` and per-run cost logging, but these capabilities are not prerequisites to producing non-zero accuracy in Phase 1. The requirement introduces tooling work (log parsing, cost estimation, flag-on-exceed logic) that is orthogonal to the Phase 1 blocking issue (output format alignment). Bundling cost tracking into Phase 1 expands the Phase 1 deliverable beyond what is necessary to unblock Phase 2.", "why_it_matters": "Phase 1 is already blocked on FR-ARCH-1 and FR-ARCH-3. Adding FR-ARCH-5 to the same phase increases the chance that Phase 1 completion is delayed by non-critical tooling. Cost tracking matters, but not before there are any findings to count.", "suggestion": "Scope FR-ARCH-5 to Phase 1.5 or Phase 2. For Phase 1, a lighter acceptance criterion is sufficient: 'Single eval run cost reviewed manually after first successful run.' Add a note that automated cost tracking is a Phase 1.5 prerequisite to enable multi-model comparison safely."}
{"type": "finding", "id": "scope-guardian-003", "title": "FR-ARCH-4 document hash validation overlaps with Phase 2 infrastructure", "severity": "Minor", "phase": {"primary": "calibrate", "contributing": null}, "section": "FR-ARCH-4: Ground Truth Refresh Cadence", "issue": "The acceptance criterion requiring `make validate` to re-run automatically when the document hash differs from the stored hash introduces automated refresh detection. This is infrastructure work beyond what Phase 1 needs. Phase 1 requires awareness of refresh triggers and a documented manual process; automated hash-based re-validation belongs in the same phase as LLM-as-judge infrastructure (Phase 2), where ground truth accuracy is critical for judge calibration.", "why_it_matters": "Automating document drift detection before the eval framework produces non-zero accuracy means building safeguards around a broken system. If Phase 1 fails to produce findings, the hash check adds no value. The manual process (document the refresh triggers) is sufficient until Phase 1 is stable.", "suggestion": "Split FR-ARCH-4 into two parts: (a) Phase 1 — document refresh triggers in a CONTRIBUTING or dataset README, no automation; (b) Phase 2 — add `design_doc_hash` to metadata.json and `make validate` hash check before LLM-as-judge grading. Scope the automated acceptance criterion to Phase 2."}
{"type": "finding", "id": "scope-guardian-004", "title": "Open question on ground truth size left unresolved — blocks Phase 1 scope definition", "severity": "Critical", "phase": {"primary": "calibrate", "contributing": null}, "section": "Open Questions (v2)", "issue": "Open Question 3 asks whether 10 validated Critical findings are sufficient for Phase 1 or whether Important findings should be added before Phase 1 completes. This is not a deferrable question — it directly determines the scope of Phase 1. If the answer is 'add Important findings,' Phase 1 scope expands. If the answer is '10 is sufficient,' the document should state that and close the question. Leaving this open makes the Phase 1 acceptance criteria for FR-ARCH-1 and FR-ARCH-3 untestable.", "why_it_matters": "FR-ARCH-1 requires per-reviewer ground truth filtering. The correct filtering behavior depends on knowing which finding severity levels are in scope for Phase 1 ground truth. A ground truth dataset that grows mid-phase will break the detection baseline and invalidate any accuracy measurements taken before expansion.", "suggestion": "Resolve this in the requirements document: specify that Phase 1 uses Critical-only ground truth (10 findings) and define a threshold for when to expand (e.g., 'add Important findings if Critical-only detection rate exceeds 85% — signals need for finer-grained signal'). Remove the question from Open Questions and record the decision with rationale."}
{"type": "finding", "id": "scope-guardian-005", "title": "Ablation decomposition question left open — affects Phase 1 task structure", "severity": "Important", "phase": {"primary": "calibrate", "contributing": null}, "section": "Open Questions (v2)", "issue": "Open Question 4 asks whether ablation tests should be decomposed per-agent or combined in Phase 1. Ablation test structure is not independent of FR-ARCH-1 (per-reviewer task decomposition) — if ablation tests are per-agent, then the `make reviewer-eval` target defined in FR-ARCH-1 must also include per-agent ablation variants. If ablation is combined, no additional tasks are needed. Leaving this open means the Phase 1 implementation scope for `evals/reviewer_eval.py` is undefined at the edges.", "why_it_matters": "Ambiguity in ablation scope means the engineer implementing Phase 1 must make a scope decision during implementation. This is scope creep risk: they may implement per-agent ablation (over-scoped) or skip it entirely (under-scoped). Neither is the right default without a decision recorded in requirements.", "suggestion": "Make a provisional decision: 'Phase 1 ablation is a single combined drop-all-persona test. Per-agent ablation is Phase 3+ aligned with fine-grained ablation already in the deferred list.' Record this in the phase map and remove from Open Questions."}
{"type": "finding", "id": "scope-guardian-006", "title": "FR-QUALITY-1 rubric validation criterion is unbounded — no min example count specified", "severity": "Minor", "phase": {"primary": "calibrate", "contributing": null}, "section": "FR-QUALITY-1: Quality Rubric Definition (Phase 2 Prerequisite)", "issue": "The acceptance criterion states 'Rubric validated against existing ground truth findings before scoring new findings' but does not specify how many examples are required to validate each rubric dimension. Without a minimum, 'validated' is satisfied by checking one finding per dimension (5 examples total). This is insufficient to confirm the rubric is consistent across finding types, severities, and reviewer styles.", "why_it_matters": "A rubric validated against too few examples will produce inconsistent LLM-as-judge scores. The judge will be calibrated to edge cases, not representative findings. This undermines Phase 2's core value proposition (consistent quality measurement). The rubric definition phase is the low-cost moment to get this right — fixing inconsistent rubrics after Phase 2 is implemented requires re-grading all historical findings.", "suggestion": "Add an acceptance criterion: 'Rubric validated against at least 3 examples per dimension (1 low/1 mid/1 high quality example), drawn from existing ground truth dataset. Validation documented in rubric file.' This is achievable with the 10-finding ground truth dataset already in place."}
{"type": "finding", "id": "scope-guardian-007", "title": "Reviewer consensus deduplication (Open Q2) affects FR-ARCH-1 ground truth filtering", "severity": "Important", "phase": {"primary": "calibrate", "contributing": null}, "section": "Open Questions (v2)", "issue": "Open Question 2 asks whether multi-reviewer findings on the same root cause should be deduplicated to one ground truth finding or kept separate per reviewer. This is not a deferred question — FR-ARCH-1's acceptance criterion requires each per-reviewer task to 'filter ground truth to findings where reviewer == agent_name.' If duplicates exist across reviewers in the ground truth dataset, the same root-cause finding would count toward multiple reviewers' detection score, inflating overall recall. If they are deduplicated, one reviewer's task has the finding and others don't, which may not reflect their actual overlap.", "why_it_matters": "Ground truth dataset structure directly determines what FR-ARCH-1's per-reviewer filtering produces. A decision made mid-Phase-1-implementation will require dataset changes and re-filtering logic changes simultaneously. This is the kind of late-binding scope ambiguity that causes rework.", "suggestion": "Resolve with a provisional decision: 'Keep separate per-reviewer entries when multiple reviewers independently flag the same root cause — preserves attribution clarity and reflects each agent's actual detection. Synthesis-level deduplication is the synthesizer agent's job, not the ground truth dataset's job.' Record the decision and close the open question."}
{"type": "finding", "id": "scope-guardian-008", "title": "Post-review implementation discovery dataset is scoped ambiguously", "severity": "Minor", "phase": {"primary": "calibrate", "contributing": null}, "section": "Open Questions (v2)", "issue": "Open Question 1 asks whether post-review findings discovered during implementation should be added to a separate 'implementation discovery' dataset. FR-ARCH-4 already states these findings are stored separately with `\"discovery\": \"implementation\"` and excluded from per-reviewer task ground truth. If FR-ARCH-4 already answers the structural question, Open Question 1 is only asking about tracking future misses — which is a Phase 4+ concern (aligned with blind spot detection, already deferred). The open question implies more scope ambiguity than actually exists.", "why_it_matters": "If an implementer reads Open Question 1 as unresolved infrastructure scope, they may add dataset tooling for implementation-discovery tracking in Phase 1. This is out of scope. The question should be closed or clearly marked as a Phase 4+ investigation.", "suggestion": "Close Open Question 1 with: 'FR-ARCH-4 handles the storage format. Tracking patterns across implementation-discovery findings is a Phase 4+ concern, aligned with blind spot detection (Issue #34). No additional Phase 1 scope.'"}
